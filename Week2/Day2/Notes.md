ğŸ“Š Day 2: Pandas â€“ Data Cleaning ğŸ§¹ & Transformation ğŸ”„
ğŸ” Topic 1: Handling Missing Data ğŸ•³ï¸ (NA Values)
ğŸ¯ Core Concept
Missing data ğŸ“‰ (NaN, None, null) appears when information is incomplete ğŸ§©. Pandas provides powerful tools ğŸ› ï¸ to detect âœ…, remove âŒ, and fill ğŸ“ these gaps.

ğŸ”§ Key Functions
1ï¸âƒ£ isnull() ğŸ” - Detect Missing Values
Returns True âœ… where data is missing, False âŒ where present.

import pandas as pd
import numpy as np

# ğŸ“¦ Create sample data with missing values
data = {'Name': ['Alice', 'Bob', None, 'David'],
        'Age': [25, np.nan, 30, 28],
        'Salary': [50000, 60000, np.nan, 55000]}
df = pd.DataFrame(data)

# ğŸ” Check for missing values (returns boolean DataFrame)
print(df.isnull())
#     Name    Age  Salary
# 0  False  False   False
# 1  False   True   False  âš ï¸ Age is missing
# 2   True  False    True  âš ï¸ Name & Salary missing
# 3  False  False   False

# ğŸ“Š Count missing values per column
print(df.isnull().sum())
# Name      1  ğŸ•³ï¸
# Age       1  ğŸ•³ï¸
# Salary    1  ğŸ•³ï¸
2ï¸âƒ£ dropna() ğŸ—‘ï¸ - Remove Missing Data
Eliminates rows â†”ï¸ or columns â†•ï¸ containing missing values.

# âŒ Drop rows with ANY missing value
df_clean = df.dropna()
print(df_clean)
#     Name  Age   Salary
# 0  Alice   25  50000.0  âœ… Only complete row remains

# âŒ Drop rows where ALL values are missing
df_partial = df.dropna(how='all')

# âŒ Drop rows with missing values in specific columns ğŸ¯
df_age_clean = df.dropna(subset=['Age'])

# âš ï¸ Drop columns (axis=1) with missing data
df_col_clean = df.dropna(axis=1)
3ï¸âƒ£ fillna() ğŸ“ - Fill Missing Values
Replaces missing data ğŸ•³ï¸ with specified values or strategies ğŸ².

# ğŸ“Œ Fill with a specific value
df_filled = df.fillna(0)  # Replace NaN with 0ï¸âƒ£

# ğŸ“Š Fill with column mean (for numerical data)
df['Age'] = df['Age'].fillna(df['Age'].mean())

# ğŸ”„ Forward fill - use previous valid value
df_ffill = df.fillna(method='ffill')

# ğŸ”™ Backward fill - use next valid value
df_bfill = df.fillna(method='bfill')

# ğŸ“– Fill different columns with different values
df_custom = df.fillna({'Name': 'Unknown', 'Age': 0, 'Salary': df['Salary'].median()})
ğŸ¯ Topic 2: Data Filtering ğŸ” (Boolean Indexing)
ğŸ¯ Core Concept
Filtering ğŸ” means selecting specific rows ğŸ“‹ based on conditions âš–ï¸. Boolean indexing uses True/False âœ…âŒ masks to extract data.

# ğŸ“¦ Sample data
data = {'Product': ['Laptop', 'Phone', 'Tablet', 'Monitor', 'Keyboard'],
        'Price': [1000, 800, 400, 300, 50],
        'Stock': [15, 30, 0, 10, 100],
        'Rating': [4.5, 4.8, 4.2, 4.0, 3.8]}
df = pd.DataFrame(data)

# ğŸ” Single condition - Products over $500 ğŸ’°
expensive = df[df['Price'] > 500]
print(expensive)
#   Product  Price  Stock  Rating
# 0  Laptop   1000     15     4.5  ğŸ’»
# 1   Phone    800     30     4.8  ğŸ“±

# ğŸ”— Multiple conditions with AND (&) operator
# Products > $300 AND Stock > 0 ğŸ“¦âœ…
available_expensive = df[(df['Price'] > 300) & (df['Stock'] > 0)]

# ğŸ”— Multiple conditions with OR (|) operator  
# Price < $100 OR Rating > 4.5 â­
cheap_or_rated = df[(df['Price'] < 100) | (df['Rating'] > 4.5)]

# ğŸš« NOT condition with ~ operator
# Products NOT out of stock âŒğŸ“¦
in_stock = df[~(df['Stock'] == 0)]

# ğŸ“‹ Using isin() for multiple value matching ğŸ¯
selected = df[df['Product'].isin(['Laptop', 'Phone', 'Monitor'])]

# ğŸ”¤ String filtering with str methods
phones = df[df['Product'].str.contains('Phone')]  # Contains "Phone" ğŸ“±
ğŸ“Š Topic 3: Sorting ğŸ”¢ & Ranking ğŸ†
ğŸ¯ Core Concept
Sorting ğŸ“ˆğŸ“‰ arranges data in ascending â¬†ï¸ or descending â¬‡ï¸ order. Ranking ğŸ¥‡ğŸ¥ˆğŸ¥‰ assigns positions based on values.

1ï¸âƒ£ sort_values() ğŸ”„ - Sort DataFrame
# ğŸ“¦ Sample data
data = {'Student': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],
        'Math': [85, 92, 78, 92, 88],
        'Science': [90, 85, 95, 80, 92]}
df = pd.DataFrame(data)

# â¬†ï¸ Sort by single column (ascending by default)
df_sorted = df.sort_values('Math')
print(df_sorted)
#    Student  Math  Science
# 2  Charlie    78       95  ğŸ“Š Lowest
# 0    Alice    85       90
# 4      Eve    88       92
# 1      Bob    92       85  ğŸ“ˆ Tied highest
# 3    David    92       80  ğŸ“ˆ Tied highest

# â¬‡ï¸ Sort in descending order
df_desc = df.sort_values('Math', ascending=False)

# ğŸ”— Sort by multiple columns ğŸ“‹
# First by Math â¬‡ï¸, then by Science â¬‡ï¸ for ties
df_multi = df.sort_values(['Math', 'Science'], ascending=[False, False])

# ğŸ”„ Sort index instead of values
df_index_sorted = df.sort_index()
2ï¸âƒ£ rank() ğŸ† - Assign Ranks
# ğŸ¥‡ Assign ranks (1 = highest by default for ascending)
df['Math_Rank'] = df['Math'].rank(ascending=False)
print(df)
#    Student  Math  Science  Math_Rank
# 0    Alice    85       90        4.0  ğŸ¥‰
# 1      Bob    92       85        1.5  ğŸ¥‡ (tied)
# 2  Charlie    78       95        5.0  ğŸ“Š
# 3    David    92       80        1.5  ğŸ¥‡ (tied)
# 4      Eve    88       92        3.0  ğŸ¥ˆ

# ğŸ¯ Handle ties differently
df['Rank_Min'] = df['Math'].rank(method='min', ascending=False)      # Both get 1 ğŸ¥‡ğŸ¥‡
df['Rank_Dense'] = df['Math'].rank(method='dense', ascending=False)  # 1, 2, 3 (no gaps) ğŸ“Š
df['Rank_First'] = df['Math'].rank(method='first', ascending=False)  # Order by appearance ğŸ”¢
ğŸ”¤ Topic 4: String Functions ğŸ“ (Text Manipulation)
ğŸ¯ Core Concept
The .str accessor provides methods ğŸ› ï¸ to manipulate text ğŸ“„ in DataFrame columns, similar to Python ğŸ string methods.

# ğŸ“¦ Sample data with text
data = {'Email': ['alice@GMAIL.com', 'bob@yahoo.com', 'charlie@OUTLOOK.com'],
        'Name': ['  Alice  ', 'Bob', 'Charlie  '],
        'Code': ['US-001', 'UK-002', 'IN-003']}
df = pd.DataFrame(data)

# ğŸ”¡ Convert to lowercase â¬‡ï¸
df['Email_Lower'] = df['Email'].str.lower()
# Result: 'alice@gmail.com' âœ…

# ğŸ”  Convert to uppercase â¬†ï¸
df['Email_Upper'] = df['Email'].str.upper()

# âœ‚ï¸ Remove whitespace (leading/trailing spaces)
df['Name_Clean'] = df['Name'].str.strip()
# '  Alice  ' â¡ï¸ 'Alice' âœ¨

# ğŸ” Check if contains substring ğŸ”
df['Is_Gmail'] = df['Email'].str.contains('gmail', case=False)
# True âœ… if email contains 'gmail'

# ğŸ“ Check if starts/ends with substring
df['Starts_US'] = df['Code'].str.startswith('US')  # True/False âœ…âŒ
df['Ends_003'] = df['Code'].str.endswith('003')

# âœ‚ï¸ Split strings and extract parts ğŸ§©
df['Country'] = df['Code'].str.split('-').str[0]  # Extract 'US', 'UK', 'IN' ğŸŒ
df['Number'] = df['Code'].str.split('-').str[1]   # Extract '001', '002', '003' ğŸ”¢

# ğŸ”„ Replace text ğŸ”
df['Email_Fixed'] = df['Email'].str.replace('GMAIL', 'gmail')

# ğŸ“ Get string length ğŸ“
df['Email_Length'] = df['Email'].str.len()

# ğŸ”¤ Extract with regex (regular expressions) ğŸ¯
df['Domain'] = df['Email'].str.extract(r'@(.+)\.com')  # Extract domain name ğŸŒ
ğŸ”„ Topic 5: Data Transformation ğŸ­ (apply, map, lambda)
ğŸ¯ Core Concept
Transformation ğŸ”„ means applying functions ğŸ§® to modify data. Three main approaches: apply() ğŸ¯, map() ğŸ—ºï¸, and lambda âš¡ functions.

1ï¸âƒ£ lambda âš¡ - Anonymous Functions
# âš¡ Lambda syntax: lambda parameters: expression
# Create quick one-line functions without 'def' ğŸ“

# Example: Square a number ğŸ”¢Â²
square = lambda x: x ** 2
print(square(5))  # Output: 25 âœ…

# Example: Add two numbers â•
add = lambda x, y: x + y
print(add(3, 4))  # Output: 7 âœ…
2ï¸âƒ£ apply() ğŸ¯ - Apply Functions to Rows/Columns
# ğŸ“¦ Sample data
data = {'Price': [100, 200, 150, 300],
        'Quantity': [2, 1, 3, 2]}
df = pd.DataFrame(data)

# ğŸ¯ Apply to single column (Series) ğŸ“Š
# Add 10% tax ğŸ’°
df['Price_With_Tax'] = df['Price'].apply(lambda x: x * 1.10)

# ğŸ¯ Apply to multiple columns (axis=1 means row-wise â†”ï¸)
# Calculate total cost ğŸ§®
df['Total'] = df.apply(lambda row: row['Price'] * row['Quantity'], axis=1)

# ğŸ”§ Using custom function instead of lambda
def categorize_price(price):
    """ğŸ“Š Categorize price into budget ranges ğŸ’µ"""
    if price < 150:
        return 'Cheap ğŸ’°'  
    elif price < 250:
        return 'Medium ğŸ’µ'
    else:
        return 'Expensive ğŸ’'

df['Category'] = df['Price'].apply(categorize_price)

# ğŸ¯ Apply with multiple return values (returns Series)
def price_analysis(price):
    """ğŸ” Analyze price and return multiple metrics ğŸ“ˆ"""
    return pd.Series({
        'Discounted': price * 0.9,      # 10% off ğŸ·ï¸
        'Premium': price * 1.2          # 20% markup ğŸ’
    })

df[['Discounted', 'Premium']] = df['Price'].apply(price_analysis)
3ï¸âƒ£ map() ğŸ—ºï¸ - Map Values Using Dictionary or Function
# ğŸ“¦ Sample data
data = {'Grade': ['A', 'B', 'C', 'A', 'B'],
        'Score': [85, 70, 60, 90, 75]}
df = pd.DataFrame(data)

# ğŸ—ºï¸ Map using dictionary ğŸ“–
grade_mapping = {'A': 'Excellent ğŸŒŸ', 'B': 'Good ğŸ‘', 'C': 'Average ğŸ“Š'}
df['Performance'] = df['Grade'].map(grade_mapping)

# ğŸ—ºï¸ Map using function âš™ï¸
df['Score_Category'] = df['Score'].map(lambda x: 'Pass âœ…' if x >= 60 else 'Fail âŒ')

# âš ï¸ Note: map() only works on Series (single column)
# For DataFrame operations, use apply() or applymap() ğŸ¯
ğŸ“Š Topic 6: Aggregation ğŸ§® & Grouping ğŸ‘¥ (groupby)
ğŸ¯ Core Concept
Grouping ğŸ‘¥ splits data into categories ğŸ·ï¸, then aggregation ğŸ§® calculates statistics ğŸ“ˆ (sum â•, mean ğŸ“Š, count ğŸ”¢) for each group.

groupby() ğŸ‘¥ - Split-Apply-Combine
# ğŸ“¦ Sample sales data
data = {'Region': ['North', 'South', 'North', 'East', 'South', 'East', 'North'],
        'Product': ['Laptop', 'Phone', 'Tablet', 'Laptop', 'Phone', 'Tablet', 'Phone'],
        'Sales': [1000, 1500, 800, 1200, 1600, 900, 1100],
        'Quantity': [2, 3, 1, 2, 4, 2, 2]}
df = pd.DataFrame(data)

# ğŸ‘¥ Group by single column and aggregate ğŸ§®
region_sales = df.groupby('Region')['Sales'].sum()
print(region_sales)
# Region
# East     2100 ğŸ’°
# North    2900 ğŸ’°
# South    3100 ğŸ’° (highest sales) ğŸ†

# ğŸ“Š Multiple aggregations on grouped data
region_stats = df.groupby('Region').agg({
    'Sales': ['sum', 'mean', 'count'],     # Total â•, Average ğŸ“Š, Count ğŸ”¢
    'Quantity': ['sum', 'max']              # Total ğŸ“¦, Maximum ğŸ”
})

# ğŸ‘¥ğŸ‘¥ Group by multiple columns ğŸ”—
region_product = df.groupby(['Region', 'Product'])['Sales'].sum()
print(region_product)
# Region  Product
# East    Laptop     1200 ğŸ’»
#         Tablet      900 ğŸ“±
# North   Laptop     1000 ğŸ’»
#         Phone      1100 ğŸ“±
#         Tablet      800 ğŸ“±
# South   Phone      3100 ğŸ“± (highest) ğŸ†

# ğŸ§® Common aggregation methods ğŸ“ˆ
grouped = df.groupby('Region')
print(grouped['Sales'].mean())    # Average ğŸ“Š
print(grouped['Sales'].min())     # Minimum ğŸ“‰
print(grouped['Sales'].max())     # Maximum ğŸ“ˆ
print(grouped['Sales'].count())   # Count ğŸ”¢
print(grouped['Sales'].std())     # Standard deviation ğŸ“

# ğŸ¯ Apply custom aggregation function âš™ï¸
def sales_range(x):
    """ğŸ“Š Calculate range (max - min) ğŸ“"""
    return x.max() - x.min()

print(df.groupby('Region')['Sales'].agg(sales_range))

# ğŸ”„ Reset index after grouping to get DataFrame ğŸ“‹
result = df.groupby('Region')['Sales'].sum().reset_index()
#   Region  Sales
# 0   East   2100
# 1  North   2900
# 2  South   3100

# ğŸ­ Transform: Keep original DataFrame size ğŸ“
# Add column showing group mean ğŸ“Š for each row
df['Region_Avg'] = df.groupby('Region')['Sales'].transform('mean')
ğŸ“ Topics Learned from Day 9 ğŸ“š
â€¢ Missing Data Management ğŸ•³ï¸ğŸ”§ â€“ Detecting gaps with isnull() ğŸ”, removing with dropna() ğŸ—‘ï¸, and filling with fillna() ğŸ“ using various strategies (mean ğŸ“Š, forward-fill â¡ï¸, custom values ğŸ¯)

â€¢ Boolean Indexing & Filtering ğŸ”âš–ï¸ â€“ Selecting specific rows using conditions with & (AND), | (OR), ~ (NOT) operators, plus isin() ğŸ¯ and string matching ğŸ”¤ for precise data extraction

â€¢ Sorting & Ranking Operations ğŸ“ŠğŸ† â€“ Organizing data with sort_values() ğŸ”¢ (single/multiple columns â¬†ï¸â¬‡ï¸) and assigning competitive positions with rank() ğŸ¥‡ğŸ¥ˆğŸ¥‰ (handling ties with various methods)

â€¢ String Manipulation Tools ğŸ”¤âœ‚ï¸ â€“ Using .str accessor methods for text processing ğŸ“: case conversion ğŸ” ğŸ”¡, stripping whitespace âœ¨, splitting ğŸ§©, pattern matching ğŸ”, and regex extraction ğŸ¯

â€¢ Function Application Techniques ğŸ”„âš¡ â€“ Transforming data with apply() ğŸ¯ (row/column-wise operations â†”ï¸â†•ï¸), map() ğŸ—ºï¸ (dictionary/function mapping ğŸ“–), and lambda âš¡ (anonymous inline functions)

â€¢ Grouping & Aggregation ğŸ‘¥ğŸ§® â€“ Splitting data by categories with groupby() ğŸ·ï¸, calculating statistics ğŸ“ˆ (sum â•, mean ğŸ“Š, count ğŸ”¢, max ğŸ”, min ğŸ“‰), and using custom aggregation functions for complex analysis ğŸ“Š