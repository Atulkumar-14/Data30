# ğŸ“Š Day 1: Introduction to EDA & Data Understanding ğŸ”

---

## ğŸ¯ What is EDA and Why Does It Matter? ğŸ’¡

**Exploratory Data Analysis (EDA)** ğŸ”¬ is the **detective work** ğŸ•µï¸ of data science! Before building any fancy models ğŸ¤–, you need to **understand** ğŸ§  what your data is trying to tell you ğŸ“£.

### ğŸŒŸ Importance of EDA â­

|Why EDA? ğŸ¤”|Real-Life Example ğŸŒ|Impact ğŸ’¥|
|---|---|---|
|**Uncover patterns** ğŸ”|Finding that ice cream sales ğŸ¦ spike during summer â˜€ï¸|Better inventory planning ğŸ“¦|
|**Detect anomalies** âš ï¸|Spotting fraudulent transactions ğŸ’³ in banking data ğŸ¦|Save millions of dollars ğŸ’°|
|**Guide model selection** ğŸ¯|Understanding data distribution ğŸ“ˆ before choosing algorithm ğŸ§®|Higher accuracy âœ…|
|**Data quality check** âœ”ï¸|Finding missing values â“ or errors ğŸš« in hospital records ğŸ¥|Better decisions ğŸ“|

**ğŸ’­ Think of it like:** Before cooking ğŸ³, you check ingredients ğŸ¥•ğŸ¥šğŸ§ˆ - EDA is checking your data ingredients!

---

## ğŸ“‚ Types of Data ğŸ—‚ï¸

### 1ï¸âƒ£ **Numerical Data** ğŸ”¢ (Quantitative)

Numbers that can be measured ğŸ“ or counted ğŸ§®.

#### ğŸ”¸ **Continuous** â°

- Can take **any value** within a range ğŸ“Š
- **Examples:**
    - Temperature ğŸŒ¡ï¸: 36.5Â°C, 36.6Â°C, 36.7Â°C...
    - Height ğŸ“: 5.5 ft, 5.51 ft, 5.511 ft...
    - Salary ğŸ’µ: $50,000.50, $50,000.51...

#### ğŸ”¸ **Discrete** ğŸ²

- Only **specific values** (usually whole numbers) ğŸ”¢
- **Examples:**
    - Number of students ğŸ‘¨â€ğŸ“ğŸ‘©â€ğŸ“: 25, 26, 27 (not 25.5!)
    - Cars sold ğŸš—: 100, 101, 102 (not 100.3!)
    - Dice roll ğŸ²: 1, 2, 3, 4, 5, 6

### 2ï¸âƒ£ **Categorical Data** ğŸ·ï¸ (Qualitative)

Labels or categories ğŸ¨ that describe qualities.

#### ğŸ”¸ **Nominal** ğŸ­ (No Order)

- Categories with **no ranking** âš–ï¸
- **Examples:**
    - Colors ğŸ¨: Red ğŸ”´, Blue ğŸ”µ, Green ğŸŸ¢
    - Gender ğŸ‘¤: Male â™‚ï¸, Female â™€ï¸, Other âš§ï¸
    - City ğŸ™ï¸: Mumbai, Delhi, Patna

#### ğŸ”¸ **Ordinal** ğŸ“Š (Has Order)

- Categories with **meaningful ranking** ğŸ¥‡ğŸ¥ˆğŸ¥‰
- **Examples:**
    - Education ğŸ“: High School < Bachelor's < Master's < PhD
    - Satisfaction ğŸ˜Š: Very Unsatisfied ğŸ˜ < Neutral ğŸ˜ < Very Satisfied ğŸ˜„
    - T-shirt size ğŸ‘•: S < M < L < XL

### 3ï¸âƒ£ **Temporal Data** â° (Time-based)

Data related to **time** ğŸ• or **dates** ğŸ“….

- **Examples:**
    - Timestamps â±ï¸: 2025-10-22 14:30:00
    - Dates ğŸ“†: January 15, 2025
    - Time series ğŸ“ˆ: Stock prices ğŸ’¹ over months ğŸ“Š

**ğŸ¯ Edge Case:** A column like "Year" ğŸ“… could be numerical (2020, 2021) but represents time â°, so treat it as temporal!

---

## ğŸ¼ Understanding Dataset Structure Using Pandas ğŸ“Š

**Pandas** ğŸ¼ is your best friend for data manipulation! Think of it as **Excel on steroids** ğŸ’ª.

### ğŸ”§ **Basic Structure** ğŸ—ï¸

```python
import pandas as pd  # ğŸ“¦ Import the pandas library
import numpy as np   # ğŸ”¢ Import numpy for numerical operations

# ğŸ“ Creating a sample dataset (like a spreadsheet)
data = {
    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],           # ğŸ‘¤ Names (Categorical-Nominal)
    'Age': [25, 30, 35, 28, None],                                 # ğŸ”¢ Age (Numerical-Discrete)
    'Salary': [50000.50, 60000.75, 75000.00, 55000.25, 62000.00], # ğŸ’° Salary (Numerical-Continuous)
    'Department': ['HR', 'IT', 'Finance', 'IT', 'HR'],             # ğŸ¢ Department (Categorical-Nominal)
    'Rating': ['Good', 'Excellent', 'Average', 'Good', 'Excellent'], # â­ Rating (Categorical-Ordinal)
    'Join_Date': ['2020-01-15', '2019-05-20', '2018-03-10', '2021-07-01', '2020-11-05'] # ğŸ“… Date (Temporal)
}

df = pd.DataFrame(data)  # ğŸ“Š Convert dictionary to DataFrame (table format)
print(df)
```

**ğŸ“¤ Output:**

```
      Name   Age    Salary Department     Rating  Join_Date
0    Alice  25.0  50000.50         HR       Good 2020-01-15
1      Bob  30.0  60000.75         IT  Excellent 2019-05-20
2  Charlie  35.0  75000.00    Finance    Average 2018-03-10
3    David  28.0  55000.25         IT       Good 2021-07-01
4      Eve   NaN  62000.00         HR  Excellent 2020-11-05
```

### ğŸ” **Basic Exploration Commands** ğŸ› ï¸

```python
# ğŸ‘€ View first 3 rows (like peeking at the top of your spreadsheet)
print(df.head(3))  # ğŸ” Shows first 3 rows

# ğŸ“ Check shape (rows â†•ï¸ Ã— columns â†”ï¸)
print(f"Dataset shape: {df.shape}")  # ğŸ“ (5 rows, 6 columns)

# ğŸ“‹ Get column names (headers of your table)
print(f"Columns: {df.columns.tolist()}")  # ğŸ·ï¸ List of all column names

# ğŸ”¢ Check data types of each column
print(df.dtypes)  # ğŸ§¬ Shows if column is int64, float64, object, etc.
```

**ğŸ¯ Linear Explanation:** A DataFrame ğŸ“Š is like an Excel table ğŸ“‘ - rows are records ğŸ“ (each person), columns are features ğŸ·ï¸ (Name, Age, etc.). Each column has a **data type** ğŸ§¬ that tells Python how to handle it.

---

## ğŸ“Š Summary Statistics Using `describe()` and `info()` ğŸ“ˆ

### 1ï¸âƒ£ **The `info()` Method** â„¹ï¸ - Quick Health Check ğŸ¥

```python
# ğŸ©º Get overall information about the dataset
print(df.info())
```

**ğŸ“¤ Output:**

```
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 5 entries, 0 to 4          # ğŸ“ 5 rows total
Data columns (total 6 columns):        # ğŸ“Š 6 columns total
 #   Column      Non-Null Count  Dtype   
---  ------      --------------  -----   
 0   Name        5 non-null      object  # âœ… All 5 values present
 1   Age         4 non-null      float64 # âš ï¸ Only 4 values (1 missing!)
 2   Salary      5 non-null      float64 # âœ… All 5 values present
 3   Department  5 non-null      object  # âœ… All 5 values present
 4   Rating      5 non-null      object  # âœ… All 5 values present
 5   Join_Date   5 non-null      object  # âœ… All 5 values present
dtypes: float64(2), object(4)          # ğŸ§¬ Data types summary
memory usage: 368.0+ bytes             # ğŸ’¾ Memory footprint
```

**ğŸ”‘ What `info()` tells you:**

- âœ… Total rows and columns ğŸ“
- âœ… Column names ğŸ·ï¸
- âœ… Non-null count âš ï¸ (missing values indicator!)
- âœ… Data types ğŸ§¬
- âœ… Memory usage ğŸ’¾

**ğŸ’¡ Real-Life Use:** Like checking a patient's vital signs ğŸ©º before treatment!

### 2ï¸âƒ£ **The `describe()` Method** ğŸ“Š - Statistical Summary ğŸ”¬

```python
# ğŸ“ˆ Get statistical summary for numerical columns only
print(df.describe())
```

**ğŸ“¤ Output:**

```
             Age        Salary
count   4.000000      5.000000  # ğŸ”¢ Number of non-null values
mean   29.500000  60500.300000  # â— Average value
std     4.203173   9258.493842  # ğŸ“Š Standard deviation (spread)
min    25.000000  50000.500000  # â¬‡ï¸ Minimum value
25%    27.250000  55000.250000  # ğŸ“ 25th percentile (Q1)
50%    29.000000  60000.750000  # ğŸ“ Median (middle value)
75%    31.250000  62000.000000  # ğŸ“ 75th percentile (Q3)
max    35.000000  75000.000000  # â¬†ï¸ Maximum value
```

**ğŸ”‘ Understanding Statistics:**

|Statistic ğŸ“Š|What it means ğŸ¤”|Real-Life Example ğŸŒ|
|---|---|---|
|**count** ğŸ”¢|How many values exist âœ…|4 people have age recorded ğŸ‘¥|
|**mean** â—|Average value ğŸ“Š|Average age is 29.5 years ğŸ‚|
|**std** ğŸ“|How spread out values are ğŸ“|Age varies by ~4.2 years ğŸ“Š|
|**min** â¬‡ï¸|Smallest value ğŸ”½|Youngest person is 25 ğŸ‘¶|
|**25%** (Q1) ğŸ“|25% of data below this ğŸ“‰|25% earn â‰¤ $55,000 ğŸ’°|
|**50%** (Median) ğŸ¯|Middle value âš–ï¸|Half earn â‰¤ $60,000 ğŸ’µ|
|**75%** (Q3) ğŸ“|75% of data below this ğŸ“ˆ|75% earn â‰¤ $62,000 ğŸ’°|
|**max** â¬†ï¸|Largest value ğŸ”¼|Highest salary is $75,000 ğŸ’|

```python
# ğŸ“Š Include categorical columns in describe
print(df.describe(include='all'))  # ğŸŒ Shows stats for ALL columns
```

**ğŸ“¤ Output (partial):**

```
         Name   Age  ...  Department     Rating
count       5   4.0  ...           5          5
unique      5   NaN  ...           3          3  # ğŸ¨ Number of unique values
top     Alice   NaN  ...          HR  Excellent  # ğŸ† Most frequent value
freq        1   NaN  ...           2          2  # ğŸ”¢ Frequency of top value
```

**ğŸ¯ Edge Case:** For categorical data ğŸ·ï¸, `describe()` shows:

- **unique** ğŸ¨: How many different categories
- **top** ğŸ†: Most common category
- **freq** ğŸ”¢: How many times top appears

---

## ğŸš¨ Handling Missing Values â“ - The Data Cleaning Challenge ğŸ§¹

**Missing values** âŒ are like **blank spaces** â¬œ in your data - they need special attention! ğŸ¯

### ğŸ” **Detecting Missing Values** ğŸ•µï¸

```python
# â“ Check for missing values (returns True/False for each cell)
print(df.isnull())  # ğŸ” Shows True where data is missing

# ğŸ“Š Count missing values per column
print(df.isnull().sum())  # ğŸ”¢ Total missing values in each column
```

**ğŸ“¤ Output:**

```
Name          0  # âœ… No missing values
Age           1  # âš ï¸ 1 missing value
Salary        0  # âœ… No missing values
Department    0  # âœ… No missing values
Rating        0  # âœ… No missing values
Join_Date     0  # âœ… No missing values
```

```python
# ğŸ“ˆ Percentage of missing values (more intuitive!)
missing_percentage = (df.isnull().sum() / len(df)) * 100  # ğŸ§® Calculate percentage
print(missing_percentage)
```

**ğŸ“¤ Output:**

```
Name           0.0%  # âœ… Perfect!
Age           20.0%  # âš ï¸ 20% missing (1 out of 5)
Salary         0.0%  # âœ… Perfect!
```

### ğŸ› ï¸ **Handling Strategies** ğŸ¯

#### **Strategy 1ï¸âƒ£: Drop Missing Values** ğŸ—‘ï¸ (Delete rows/columns)

```python
# âŒ Drop rows with ANY missing value
df_dropped_rows = df.dropna()  # ğŸ—‘ï¸ Removes entire row if any value is missing
print(f"Original rows: {len(df)}, After dropping: {len(df_dropped_rows)}")  # ğŸ“‰ 5 â†’ 4 rows

# âŒ Drop columns with missing values
df_dropped_cols = df.dropna(axis=1)  # ğŸ—‘ï¸ Removes entire column if any value is missing
print(f"Original columns: {len(df.columns)}, After dropping: {len(df_dropped_cols.columns)}")  # ğŸ“‰ 6 â†’ 5 columns

# ğŸ¯ Drop only if ALL values in a row are missing (safer!)
df_dropped_all = df.dropna(how='all')  # ğŸ›¡ï¸ Only removes rows that are completely empty
```

**âš ï¸ Warning:** Dropping data means **losing information** ğŸ“‰! Use carefully!

**ğŸŒ Real-Life Decision:**

- If only 1% missing â¡ï¸ Drop it ğŸ—‘ï¸
- If 50% missing â¡ï¸ Don't drop, fill it! ğŸ”§

#### **Strategy 2ï¸âƒ£: Fill Missing Values** ğŸ”§ (Imputation)

```python
# ğŸ“Š Fill with mean (average) - for numerical data
df['Age_filled_mean'] = df['Age'].fillna(df['Age'].mean())  # â— Fill with average age (29.5)

# ğŸ“ Fill with median (middle value) - better for outliers
df['Age_filled_median'] = df['Age'].fillna(df['Age'].median())  # ğŸ¯ Fill with median age (29.0)

# ğŸ”¢ Fill with mode (most frequent) - for categorical data
df['Department_filled'] = df['Department'].fillna(df['Department'].mode()[0])  # ğŸ† Fill with most common department

# ğŸ“ Fill with custom value
df['Age_filled_custom'] = df['Age'].fillna(0)  # 0ï¸âƒ£ Fill with 0 (or any value you choose)

# â­ï¸ Forward fill - copy previous value
df['Age_ffill'] = df['Age'].fillna(method='ffill')  # â© Copy value from row above

# â®ï¸ Backward fill - copy next value
df['Age_bfill'] = df['Age'].fillna(method='bfill')  # âª Copy value from row below

print(df)
```

**ğŸ¯ Which Method to Use? ğŸ¤”**

|Data Type ğŸ§¬|Missing Strategy ğŸ› ï¸|Reasoning ğŸ’­|
|---|---|---|
|**Numerical (Continuous)** ğŸ”¢|Median ğŸ“ or Mean â—|Median better if outliers exist ğŸ“Š|
|**Numerical (Discrete)** ğŸ²|Mode ğŸ† or Median ğŸ“|Mode preserves discrete nature ğŸ¯|
|**Categorical** ğŸ·ï¸|Mode ğŸ†|Most common category makes sense ğŸ¨|
|**Time Series** â°|Forward/Backward Fill â­ï¸â®ï¸|Maintains temporal continuity ğŸ“ˆ|

**ğŸŒ Real-Life Example:**

- Missing age ğŸ‚ in customer data â¡ï¸ Fill with median age ğŸ“ (29 years)
- Missing rating â­ â¡ï¸ Fill with mode ğŸ† ("Good" if most common)
- Missing timestamp â° â¡ï¸ Forward fill â© (use previous time)

### ğŸ§¹ **Basic Data Cleaning** âœ¨

```python
# ğŸ” Check for duplicate rows
print(f"Duplicate rows: {df.duplicated().sum()}")  # ğŸ”¢ Count duplicates

# ğŸ—‘ï¸ Remove duplicate rows
df_clean = df.drop_duplicates()  # ğŸ§¹ Keep only unique rows

# âœ‚ï¸ Remove leading/trailing spaces from string columns
df['Name'] = df['Name'].str.strip()  # ğŸ§¼ Clean whitespace: "  Alice  " â†’ "Alice"

# ğŸ”¡ Convert to lowercase for consistency
df['Department'] = df['Department'].str.lower()  # ğŸ“ "HR" â†’ "hr", "IT" â†’ "it"

# ğŸ“… Convert date strings to datetime objects
df['Join_Date'] = pd.to_datetime(df['Join_Date'])  # â° Converts string to proper date format

# ğŸ·ï¸ Rename columns for clarity
df = df.rename(columns={'Name': 'Employee_Name', 'Age': 'Employee_Age'})  # âœï¸ Better naming

print(df.info())  # â„¹ï¸ Check if cleaning worked!
```

**ğŸ¯ Edge Case - Multiple Issues:** ğŸš¨

```python
# ğŸŒ Real messy data example
messy_data = {
    'name': ['  Alice  ', 'BOB', 'alice', 'Charlie', 'Charlie'],  # ğŸ­ Spacing, case issues, duplicates
    'salary': [50000, None, 60000, 75000, 75000],                # â“ Missing value
    'email': ['alice@ex.com', 'bob@ex', 'alice@ex.com', None, None]  # â“ Multiple missing
}
df_messy = pd.DataFrame(messy_data)

# ğŸ§¹ Comprehensive cleaning
df_messy['name'] = df_messy['name'].str.strip().str.lower()  # âœ¨ Remove spaces + lowercase
df_messy['salary'] = df_messy['salary'].fillna(df_messy['salary'].median())  # ğŸ’° Fill missing with median
df_messy = df_messy.drop_duplicates()  # ğŸ—‘ï¸ Remove duplicate rows
df_messy = df_messy.dropna(subset=['email'])  # âŒ Drop rows where email is missing

print(df_messy)
```

---

## ğŸ“ What We Learned Today ğŸ“š

â€¢ **EDA is Detective Work** ğŸ•µï¸ â†’ Understanding data before modeling ğŸ¤– â†’ Like checking ingredients ğŸ¥• before cooking ğŸ³ â†’ Uncovers patterns ğŸ”, detects errors âš ï¸, guides decisions ğŸ¯

â€¢ **Three Data Types** ğŸ—‚ï¸ â†’ Numerical ğŸ”¢ (continuous â° like temperature ğŸŒ¡ï¸, discrete ğŸ² like counts), Categorical ğŸ·ï¸ (nominal ğŸ­ like colors ğŸ¨, ordinal ğŸ“Š like ratings â­), Temporal â° (dates ğŸ“… and timestamps â±ï¸)

â€¢ **Pandas DataFrame** ğŸ¼ â†’ Like Excel on steroids ğŸ’ª â†’ Use `head()` ğŸ‘€, `shape` ğŸ“, `columns` ğŸ·ï¸, `dtypes` ğŸ§¬ â†’ Quick exploration of data structure ğŸ—ï¸ and organization ğŸ“Š

â€¢ **Summary Statistics** ğŸ“ˆ â†’ `info()` â„¹ï¸ shows health check ğŸ©º (null counts â“, data types ğŸ§¬, memory ğŸ’¾) â†’ `describe()` ğŸ“Š shows math ğŸ”¢ (mean â—, median ğŸ“, std ğŸ“, quartiles ğŸ¯) â†’ Reveals data distribution ğŸ“‰ and quality âœ…

â€¢ **Missing Values Handling** ğŸš¨ â†’ Detect with `isnull()` ğŸ” â†’ Drop ğŸ—‘ï¸ with `dropna()` (loses info âš ï¸) â†’ Fill ğŸ”§ with `fillna()` (mean â—, median ğŸ“, mode ğŸ†, forward/backward â­ï¸â®ï¸) â†’ Choose strategy based on data type ğŸ§¬ and percentage missing ğŸ“Š

â€¢ **Data Cleaning Essentials** ğŸ§¹ â†’ Remove duplicates ğŸ—‘ï¸ with `drop_duplicates()` â†’ Clean strings âœ‚ï¸ with `strip()` and `lower()` ğŸ”¡ â†’ Convert types ğŸ“… with `to_datetime()` â° â†’ Better column names âœï¸ with `rename()` ğŸ·ï¸